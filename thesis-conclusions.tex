% -*- mode:LaTex; mode:visual-line; mode:flyspell; fill-column:75-*-

\chapter{Conclusions and Future Work} \label{chap:conclusion}

\section{Conclusion}
In this thesis, I have investigated and presented a system for SLAM with higher level object landmarks, that provide both robust data association, and enable accurate trajectory estimation, and object reconstruction.

In this system, I develop a fast coarse-to-fine ICP to estimate initializations for the frame poses, I present an efficient method for composing renders as simple alpha matting between individual object renders, and I present a simple data association method that uses both geometric (the IoU metric or projective overlap) and semantic information (the object feature from the segmentation pipeline). Finally, combining these pieces in an factor graph optimization framework allows us to seamlessly correct for drift in the object poses -- as rigid bodies. Finally, experimental results validated tht our approach is both comparable to existing geometric SLAM methods and better than existing Object SLAM methods in terms of trajectory accuracy. We also presented qualitative results of object reconstruction.

\section{Limitation and Future work}

In this work, I have developed a system for scene reconstruction as a posegraph of objects.

To obtain the object masks and initializations we have resorted to existing semantic instance segmentation pipelines~\cite{kirillovPointRendImageSegmentation2020}, and utilized geometric TSDF fusion as the method to integrate these measurements. Current deep learning based semantic segmentation pipelines introduce different types of errors:
\begin{enumerate}
    \item Label inaccuracy: Since instance segmentation is trained only on single images, there exists no notion of temporal consistency of label predictions between frames. While we have alleviated this issue by comparing the object features and IoU between frames, this issue is far from solved. If we assume that the model label output to be a  categorical distribution, we may simply calculate the label of the fused data as the \emph{mode} of the distribution. Note that in our method we use the object label only for pedagogical purposes and not for data association.
    \item Mask inaccuracy: Our method quite heavily relies on the IoU metric for data association, which consequently assumes that the deep learning model generates similar masks for objects in temporally close frames. This assumption is violated in some cases, and results in multiple object landmark initializations. While we prune these objects by maintaining an existence probability for each object, we lose the information that was fused into these erroneous objects.
\end{enumerate}

Research progress in this aspect requires use of segmentation pipelines that are explicitly trained for temporal consistency i.e., and trained on videos rather than individual images.

In this thesis, we update and integrate objects using geometric TSDF fusion, and do not utilize inductive biases from the object level inference to inpaint unseen parts of the object.

A potential direction of future work is to use a neural mapping representation that is capable of model completion for the objects. Recent improvements in implicit neural representations for scenes such as~\cite{parkDeepSDFLearningContinuous2019, mildenhallNeRFRepresentingScenes2020} provide rich avenues to explore. Since neural networks are excellent function approximators, using them to represent 3D surface manifolds is a reasonable approach, that provides the additional benefit of imbuing object inductive biases.

Finally, we know that object landmarks are a rich description of the environment, and reduce the computational load in factor graph optimization significantly by reducing the number of factors in a pose graph. In addition to the proposed research directions, I am also excited to apply object based SLAM systems for multi-robot distributed inference, where distributed computation requires minimal factor sharing between robots.
